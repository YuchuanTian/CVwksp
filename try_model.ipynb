{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'timm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-00946f5bb4a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtimm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtimm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'timm'"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "timm.list_models()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model('tnt_b_patch16_224',num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TNT(\n",
       "  (pixel_embed): PixelEmbed(\n",
       "    (proj): Conv2d(3, 40, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))\n",
       "    (unfold): Unfold(kernel_size=[4, 4], dilation=1, padding=0, stride=[4, 4])\n",
       "  )\n",
       "  (norm1_proj): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "  (proj): Linear(in_features=640, out_features=640, bias=True)\n",
       "  (norm2_proj): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "  (blocks): ModuleList(\n",
       "    (0): Block(\n",
       "      (norm_in): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn_in): Attention(\n",
       "        (qk): Linear(in_features=40, out_features=80, bias=False)\n",
       "        (v): Linear(in_features=40, out_features=40, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=True)\n",
       "        (proj): Linear(in_features=40, out_features=40, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=True)\n",
       "      )\n",
       "      (norm_mlp_in): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_in): Mlp(\n",
       "        (fc1): Linear(in_features=40, out_features=160, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=160, out_features=40, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (norm1_proj): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "      (proj): Linear(in_features=640, out_features=640, bias=True)\n",
       "      (norm_out): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn_out): Attention(\n",
       "        (qk): Linear(in_features=640, out_features=1280, bias=False)\n",
       "        (v): Linear(in_features=640, out_features=640, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=True)\n",
       "        (proj): Linear(in_features=640, out_features=640, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=True)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm_mlp): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=640, out_features=2560, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Block(\n",
       "      (norm_in): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn_in): Attention(\n",
       "        (qk): Linear(in_features=40, out_features=80, bias=False)\n",
       "        (v): Linear(in_features=40, out_features=40, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=True)\n",
       "        (proj): Linear(in_features=40, out_features=40, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=True)\n",
       "      )\n",
       "      (norm_mlp_in): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_in): Mlp(\n",
       "        (fc1): Linear(in_features=40, out_features=160, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=160, out_features=40, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (norm1_proj): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "      (proj): Linear(in_features=640, out_features=640, bias=True)\n",
       "      (norm_out): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn_out): Attention(\n",
       "        (qk): Linear(in_features=640, out_features=1280, bias=False)\n",
       "        (v): Linear(in_features=640, out_features=640, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=True)\n",
       "        (proj): Linear(in_features=640, out_features=640, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=True)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm_mlp): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=640, out_features=2560, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2): Block(\n",
       "      (norm_in): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn_in): Attention(\n",
       "        (qk): Linear(in_features=40, out_features=80, bias=False)\n",
       "        (v): Linear(in_features=40, out_features=40, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=True)\n",
       "        (proj): Linear(in_features=40, out_features=40, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=True)\n",
       "      )\n",
       "      (norm_mlp_in): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_in): Mlp(\n",
       "        (fc1): Linear(in_features=40, out_features=160, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=160, out_features=40, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (norm1_proj): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "      (proj): Linear(in_features=640, out_features=640, bias=True)\n",
       "      (norm_out): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn_out): Attention(\n",
       "        (qk): Linear(in_features=640, out_features=1280, bias=False)\n",
       "        (v): Linear(in_features=640, out_features=640, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=True)\n",
       "        (proj): Linear(in_features=640, out_features=640, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=True)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm_mlp): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=640, out_features=2560, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (3): Block(\n",
       "      (norm_in): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn_in): Attention(\n",
       "        (qk): Linear(in_features=40, out_features=80, bias=False)\n",
       "        (v): Linear(in_features=40, out_features=40, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=True)\n",
       "        (proj): Linear(in_features=40, out_features=40, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=True)\n",
       "      )\n",
       "      (norm_mlp_in): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_in): Mlp(\n",
       "        (fc1): Linear(in_features=40, out_features=160, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=160, out_features=40, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (norm1_proj): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "      (proj): Linear(in_features=640, out_features=640, bias=True)\n",
       "      (norm_out): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn_out): Attention(\n",
       "        (qk): Linear(in_features=640, out_features=1280, bias=False)\n",
       "        (v): Linear(in_features=640, out_features=640, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=True)\n",
       "        (proj): Linear(in_features=640, out_features=640, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=True)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm_mlp): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=640, out_features=2560, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (4): Block(\n",
       "      (norm_in): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn_in): Attention(\n",
       "        (qk): Linear(in_features=40, out_features=80, bias=False)\n",
       "        (v): Linear(in_features=40, out_features=40, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=True)\n",
       "        (proj): Linear(in_features=40, out_features=40, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=True)\n",
       "      )\n",
       "      (norm_mlp_in): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_in): Mlp(\n",
       "        (fc1): Linear(in_features=40, out_features=160, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=160, out_features=40, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (norm1_proj): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "      (proj): Linear(in_features=640, out_features=640, bias=True)\n",
       "      (norm_out): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn_out): Attention(\n",
       "        (qk): Linear(in_features=640, out_features=1280, bias=False)\n",
       "        (v): Linear(in_features=640, out_features=640, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=True)\n",
       "        (proj): Linear(in_features=640, out_features=640, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=True)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm_mlp): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=640, out_features=2560, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (5): Block(\n",
       "      (norm_in): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn_in): Attention(\n",
       "        (qk): Linear(in_features=40, out_features=80, bias=False)\n",
       "        (v): Linear(in_features=40, out_features=40, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=True)\n",
       "        (proj): Linear(in_features=40, out_features=40, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=True)\n",
       "      )\n",
       "      (norm_mlp_in): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_in): Mlp(\n",
       "        (fc1): Linear(in_features=40, out_features=160, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=160, out_features=40, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (norm1_proj): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "      (proj): Linear(in_features=640, out_features=640, bias=True)\n",
       "      (norm_out): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn_out): Attention(\n",
       "        (qk): Linear(in_features=640, out_features=1280, bias=False)\n",
       "        (v): Linear(in_features=640, out_features=640, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=True)\n",
       "        (proj): Linear(in_features=640, out_features=640, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=True)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm_mlp): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=640, out_features=2560, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (6): Block(\n",
       "      (norm_in): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn_in): Attention(\n",
       "        (qk): Linear(in_features=40, out_features=80, bias=False)\n",
       "        (v): Linear(in_features=40, out_features=40, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=True)\n",
       "        (proj): Linear(in_features=40, out_features=40, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=True)\n",
       "      )\n",
       "      (norm_mlp_in): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_in): Mlp(\n",
       "        (fc1): Linear(in_features=40, out_features=160, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=160, out_features=40, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (norm1_proj): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "      (proj): Linear(in_features=640, out_features=640, bias=True)\n",
       "      (norm_out): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn_out): Attention(\n",
       "        (qk): Linear(in_features=640, out_features=1280, bias=False)\n",
       "        (v): Linear(in_features=640, out_features=640, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=True)\n",
       "        (proj): Linear(in_features=640, out_features=640, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=True)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm_mlp): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=640, out_features=2560, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (7): Block(\n",
       "      (norm_in): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn_in): Attention(\n",
       "        (qk): Linear(in_features=40, out_features=80, bias=False)\n",
       "        (v): Linear(in_features=40, out_features=40, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=True)\n",
       "        (proj): Linear(in_features=40, out_features=40, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=True)\n",
       "      )\n",
       "      (norm_mlp_in): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_in): Mlp(\n",
       "        (fc1): Linear(in_features=40, out_features=160, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=160, out_features=40, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (norm1_proj): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "      (proj): Linear(in_features=640, out_features=640, bias=True)\n",
       "      (norm_out): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn_out): Attention(\n",
       "        (qk): Linear(in_features=640, out_features=1280, bias=False)\n",
       "        (v): Linear(in_features=640, out_features=640, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=True)\n",
       "        (proj): Linear(in_features=640, out_features=640, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=True)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm_mlp): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=640, out_features=2560, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (8): Block(\n",
       "      (norm_in): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn_in): Attention(\n",
       "        (qk): Linear(in_features=40, out_features=80, bias=False)\n",
       "        (v): Linear(in_features=40, out_features=40, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=True)\n",
       "        (proj): Linear(in_features=40, out_features=40, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=True)\n",
       "      )\n",
       "      (norm_mlp_in): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_in): Mlp(\n",
       "        (fc1): Linear(in_features=40, out_features=160, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=160, out_features=40, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (norm1_proj): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "      (proj): Linear(in_features=640, out_features=640, bias=True)\n",
       "      (norm_out): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn_out): Attention(\n",
       "        (qk): Linear(in_features=640, out_features=1280, bias=False)\n",
       "        (v): Linear(in_features=640, out_features=640, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=True)\n",
       "        (proj): Linear(in_features=640, out_features=640, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=True)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm_mlp): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=640, out_features=2560, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (9): Block(\n",
       "      (norm_in): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn_in): Attention(\n",
       "        (qk): Linear(in_features=40, out_features=80, bias=False)\n",
       "        (v): Linear(in_features=40, out_features=40, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=True)\n",
       "        (proj): Linear(in_features=40, out_features=40, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=True)\n",
       "      )\n",
       "      (norm_mlp_in): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_in): Mlp(\n",
       "        (fc1): Linear(in_features=40, out_features=160, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=160, out_features=40, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (norm1_proj): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "      (proj): Linear(in_features=640, out_features=640, bias=True)\n",
       "      (norm_out): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn_out): Attention(\n",
       "        (qk): Linear(in_features=640, out_features=1280, bias=False)\n",
       "        (v): Linear(in_features=640, out_features=640, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=True)\n",
       "        (proj): Linear(in_features=640, out_features=640, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=True)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm_mlp): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=640, out_features=2560, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (10): Block(\n",
       "      (norm_in): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn_in): Attention(\n",
       "        (qk): Linear(in_features=40, out_features=80, bias=False)\n",
       "        (v): Linear(in_features=40, out_features=40, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=True)\n",
       "        (proj): Linear(in_features=40, out_features=40, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=True)\n",
       "      )\n",
       "      (norm_mlp_in): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_in): Mlp(\n",
       "        (fc1): Linear(in_features=40, out_features=160, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=160, out_features=40, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (norm1_proj): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "      (proj): Linear(in_features=640, out_features=640, bias=True)\n",
       "      (norm_out): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn_out): Attention(\n",
       "        (qk): Linear(in_features=640, out_features=1280, bias=False)\n",
       "        (v): Linear(in_features=640, out_features=640, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=True)\n",
       "        (proj): Linear(in_features=640, out_features=640, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=True)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm_mlp): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=640, out_features=2560, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (11): Block(\n",
       "      (norm_in): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn_in): Attention(\n",
       "        (qk): Linear(in_features=40, out_features=80, bias=False)\n",
       "        (v): Linear(in_features=40, out_features=40, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=True)\n",
       "        (proj): Linear(in_features=40, out_features=40, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=True)\n",
       "      )\n",
       "      (norm_mlp_in): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp_in): Mlp(\n",
       "        (fc1): Linear(in_features=40, out_features=160, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=160, out_features=40, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (norm1_proj): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "      (proj): Linear(in_features=640, out_features=640, bias=True)\n",
       "      (norm_out): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn_out): Attention(\n",
       "        (qk): Linear(in_features=640, out_features=1280, bias=False)\n",
       "        (v): Linear(in_features=640, out_features=640, bias=False)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=True)\n",
       "        (proj): Linear(in_features=640, out_features=640, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=True)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm_mlp): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=640, out_features=2560, bias=True)\n",
       "        (act): GELU()\n",
       "        (fc2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "  (head): Linear(in_features=640, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torchvision.models.resnet.resnet18(pretrained=False, progress=True, **kwargs)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "eval('models.resnet18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_loading import *\n",
    "\n",
    "_, dset_loader = load_data('./', 'webcam')\n",
    "\n",
    "total = 0\n",
    "\n",
    "for i, (y,x) in enumerate(dset_loader['tr']):\n",
    "    print(\"At {}: \".format(i), end='' )\n",
    "    total+= y.shape[0]\n",
    "    print(\"Total = {}\".format(total))\n",
    "\n",
    "for i, (y,x) in enumerate(dset_loader['te']):\n",
    "    print(\"At {}: \".format(i), end='' )\n",
    "    total+= y.shape[0]\n",
    "    print(\"Total = {}\".format(total))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b14e145ced79f681683730c69806dda76fd1704896cd9933b193547bb63c2cde"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('da': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
